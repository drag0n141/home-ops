---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: '3'

vars:
  BOOTSTRAP_RESOURCES_DIR: '{{.ROOT_DIR}}/.taskfiles/bootstrap/resources'

tasks:

  talos:
    desc: Bootstrap Talos [CLUSTER=main]
    dotenv: ['{{.CLUSTER_DIR}}/bootstrap/.cluster.env']
    cmds:
      - for: { var: TALOS_NODES }
        cmd: >
          sops exec-file --input-type yaml --output-type yaml {{.ITEM}} "minijinja-cli {}"
          | talosctl --nodes {{base .ITEM | replace ".sops.yaml.j2" ""}} apply-config --insecure --file /dev/stdin
      - until talosctl --nodes {{.TALOS_CONTROLLER}} bootstrap; do sleep 5; done
      - talosctl kubeconfig --nodes {{.TALOS_CONTROLLER}} --force --force-context-name {{.CLUSTER}} {{.CLUSTER_DIR}}
    vars:
      TALOS_CONTROLLER:
        sh: talosctl config info --output json | jq --raw-output '.endpoints[]' | shuf -n 1
      TALOS_NODES:
        sh: ls {{.CLUSTER_DIR}}/talos/*.j2
    requires:
      vars: [CLUSTER]
    preconditions:
      - talosctl config info
      - test -f {{.CLUSTER_DIR}}/talosconfig
      - which ls minijinja-cli sops talosctl

  apps:
    desc: Bootstrap Apps [CLUSTER=main] [ROOK_DISK=WD_BLACK_SN850X]
    cmds:
      - until kubectl wait nodes --for=condition=Ready=False --all --timeout=10m; do sleep 5; done
      - op run --env-file {{.CLUSTER_DIR}}/bootstrap/apps/.secrets.env --no-masking -- minijinja-cli {{.CLUSTER_DIR}}/bootstrap/apps/templates/resources.yaml.j2 | kubectl apply --server-side --filename -
      - helmfile --quiet --file {{.CLUSTER_DIR}}/bootstrap/apps/helmfile.yaml apply --skip-diff-on-install --suppress-diff
      - '{{if eq .CLUSTER "main"}}helmfile --quiet --file {{.CLUSTER_DIR}}/bootstrap/apps/helmfile.yaml destroy --selector name=wipe-rook{{end}}'
    vars:
      ROOK_DISK: '{{.ROOK_DISK | default "WD_BLACK_SN850X"}}'
    env:
      NODE_COUNT:
        sh: talosctl config info --output json | jq --raw-output '.nodes | length'
      ROOK_DISK: '{{.ROOK_DISK}}'
      VAULT: kubernetes
    requires:
      vars: [CLUSTER]
    preconditions:
      - op user get --me
      - talosctl config info
      - test -f {{.CLUSTER_DIR}}/bootstrap/talosconfig
      - test -f {{.CLUSTER_DIR}}/bootstrap/apps/helmfile.yaml
      - test -f {{.CLUSTER_DIR}}/bootstrap/apps/templates/resources.yaml.j2
      - test -f {{.CLUSTER_DIR}}/bootstrap/apps/templates/wipe-rook.yaml.gotmpl
      - which curl jq helmfile kubectl op talosctl

  matchbox:
    desc: Sync required Matchbox config to PXEBoot machine [CLUSTER=main]
    dotenv: ['{{.CLUSTER_DIR}}/bootstrap/.cluster.env']
    cmds:
      - ssh -l root 192.168.254.2 "sudo mkdir -p /mnt/user/appdata/matchbox/{groups,profiles,assets}"
      - ssh -l root 192.168.254.2 "sudo mkdir -p /mnt/user/appdata/matchbox/assets/{{.CLUSTER}}"
      - for: ["kernel-amd64", "initramfs-amd64.xz"]
        cmd: curl -skL https://factory.talos.dev/image/$TALOS_SCHEMATIC_ID/$TALOS_VERSION/{{.ITEM}} | curl --key /root/.ssh/id_ed25519 -skT - -u "root:" sftp://192.168.254.2//mnt/user/appdata/matchbox/assets/{{.CLUSTER}}/{{.ITEM}}
      - for: { var: ASSETS }
        cmd: sops exec-file --input-type yaml --output-type yaml {{.ITEM}} "minijinja-cli {} | curl --key /root/.ssh/id_ed25519 -skT - -u "root:" sftp://192.168.254.2//mnt/user/appdata/matchbox/assets/{{.CLUSTER}}/{{base .ITEM | replace ".sops.yaml.j2" ".yaml"}}"
      - for: { var: GROUPS }
        cmd: minijinja-cli {{.ITEM}} | curl --key /root/.ssh/id_ed25519 -skT - -u "root:" sftp://192.168.254.2//mnt/user/appdata/matchbox/groups/{{base .ITEM | replace ".json.j2" ".json"}}
      - for: { var: PROFILES }
        cmd: minijinja-cli {{.ITEM}} | curl --key /root/.ssh/id_ed25519 -skT - -u "root:" sftp://192.168.254.2//mnt/user/appdata/matchbox/profiles/{{base .ITEM | replace ".json.j2" ".json"}}
      - ssh -l root 192.168.254.2 "docker restart matchbox"
    vars:
      ASSETS:
        sh: ls {{.CLUSTER_DIR}}/bootstrap/talos/*.yaml.j2
      GROUPS:
        sh: ls {{.CLUSTER_DIR}}/bootstrap/matchbox/groups/*.json.j2
      PROFILES:
        sh: ls {{.CLUSTER_DIR}}/bootstrap/matchbox/profiles/*.json.j2
    requires:
      vars: [CLUSTER]
    preconditions:
      - ping -c1 192.168.254.2
      - which ls minijinja-cli sops
